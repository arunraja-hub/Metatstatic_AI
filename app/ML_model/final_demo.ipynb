{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Protoype demo:\n",
    "1. Used simple CNN with dropout\n",
    "2. tensorflow+keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(101)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(101)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from time import gmtime, strftime\n",
    "strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b7bbdd52c81188b8e9c528b88d9fd0da176bf4bc"
   },
   "outputs": [],
   "source": [
    "\n",
    "image_size = 96\n",
    "channels = 3\n",
    "sample_size = 50000 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9c9f40ffab35044641b0dc7d9b18609af1aa25e"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train_labels.csv')\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e18560bf69d3dfc0c4772e7c79bb119fd2eb634b"
   },
   "outputs": [],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want a equal number of samples in each class (0 and 1) to prevent class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "270fc18640b552ecc3cb0e1dd3036441db7a4a2b"
   },
   "outputs": [],
   "source": [
    "df_0 = df_train[df_train['label'] == 0].sample(sample_size, random_state = 101)\n",
    "df_1 = df_train[df_train['label'] == 1].sample(sample_size, random_state = 101)\n",
    "df_train = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
    "# shuffling to ensure random distribution of labels, especially since we will be further dividing this train set into train and valid sets\n",
    "df_train = shuffle(df_train)\n",
    "\n",
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15ba9792e6a370b7560330af15b3cfe21185c1cb"
   },
   "outputs": [],
   "source": [
    "# further dividing training data into train and validation sets\n",
    "y = df_train['label']\n",
    "#90/10% split into train and val sets\n",
    "df_train_train, df_train_val = train_test_split(df_train, test_size=0.10, random_state=101, stratify=y)\n",
    "\n",
    "print(df_train_train.shape)\n",
    "print(df_train_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, df_train size is 90000, df_val_size is 10000 with equal distributuion of 0 and 1 labels in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7de70d915a5f1d2599725e00bdb3b9103d947883"
   },
   "outputs": [],
   "source": [
    "df_train_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "392c0eea00be8e43a6e55438d1458650e842030b"
   },
   "outputs": [],
   "source": [
    "df_train_val['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new directory of subdirs to easily feed data into models via generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ff8acc2e92a1b1b5002d6e1bf9a1180c3256f19d"
   },
   "outputs": [],
   "source": [
    "# base dir\n",
    "base_dir = 'base_dir'\n",
    "os.mkdir(base_dir)\n",
    "#base_dir structure\n",
    "# train_dir\n",
    "    # val0:no tumor\n",
    "    # val1:has tumor\n",
    "\n",
    "# val_dir\n",
    "    # val0:no tumor\n",
    "    # val1:has tumor\n",
    "\n",
    "#subpaths for subdirs\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "\n",
    "val0 = os.path.join(train_dir, 'val0')\n",
    "os.mkdir(val0)\n",
    "val1 = os.path.join(train_dir, 'val1')\n",
    "os.mkdir(val1)\n",
    "\n",
    "val0 = os.path.join(val_dir, 'val0')\n",
    "os.mkdir(val0)\n",
    "val1 = os.path.join(val_dir, 'val1')\n",
    "os.mkdir(val1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e84c8a9642b030094b1888af3299063f883112a6"
   },
   "outputs": [],
   "source": [
    "# use id as index in the dataframe\n",
    "df_train.set_index('id', inplace=True)\n",
    "\n",
    "train_list = list(df_train_train['id'])\n",
    "val_list = list(df_train_val['id'])\n",
    "print(train_list[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading files into the directory created above using the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "afb8969a9ee75c13bddc808a4bcc326611baaaaf"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for image in train_list:\n",
    "    #.tif is the image format\n",
    "    fname = image + '.tif'\n",
    "    target = df_train.loc[image,'label']\n",
    "\n",
    "    if target == 0:\n",
    "        label = 'val0'\n",
    "    if target == 1:\n",
    "        label = 'val1'\n",
    "        \n",
    "    src = os.path.join('../input/train', fname)\n",
    "    dst = os.path.join(train_dir, label, fname)\n",
    "    #copy\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "for image in val_list:\n",
    "    #.tif is the image format\n",
    "    fname = image + '.tif'\n",
    "    target = df_train.loc[image,'label']\n",
    "\n",
    "    if target == 0:\n",
    "        label = 'val0'\n",
    "    if target == 1:\n",
    "        label = 'val1'\n",
    "\n",
    "    src = os.path.join('../input/train', fname)\n",
    "    dst = os.path.join(val_dir, label, fname)\n",
    "    #copy\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71532bfc32608289b1f773ffdbc8a7cea1bfb94c"
   },
   "outputs": [],
   "source": [
    "# check how many train images we have in each folder\n",
    "\n",
    "print(len(os.listdir('base_dir/train_dir/val0')))\n",
    "print(len(os.listdir('base_dir/train_dir/val1')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "897e9df543bb65b47bb00019dc681125ca08ee5d"
   },
   "outputs": [],
   "source": [
    "# check how many val images we have in each folder\n",
    "\n",
    "print(len(os.listdir('base_dir/val_dir/val0')))\n",
    "print(len(os.listdir('base_dir/val_dir/val1')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feed subdirs into generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef4fe7be09f11ff4badfd22d5fd5e03f8521ed58"
   },
   "outputs": [],
   "source": [
    "test_path = '../input/test'\n",
    "\n",
    "train_size = len(df_train_train)\n",
    "val_size = len(df_train_val)\n",
    "train_size_batch = 10\n",
    "val_size_batch = 10\n",
    "\n",
    "train_steps = np.ceil(train_size / train_size_batch)\n",
    "val_steps = np.ceil(val_size / val_size_batch)\n",
    "print(train_steps)\n",
    "print(val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68fbd9d5fbb80859a82f94a12e335ce05a93bd51"
   },
   "outputs": [],
   "source": [
    "#adapted from https://keras.io/preprocessing/image/\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_dir,\n",
    "                                        target_size=(image_size,image_size),\n",
    "                                        batch_size=train_size_batch,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "val_gen = datagen.flow_from_directory(val_dir,\n",
    "                                        target_size=(image_size,image_size),\n",
    "                                        batch_size=val_size_batch,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "\n",
    "test_gen = datagen.flow_from_directory(val_dir,\n",
    "                                        target_size=(image_size,image_size),\n",
    "                                        batch_size=1,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "79da4d0a66a90cffe40580a596dd4d0e2bc45a9b"
   },
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9835ea0fd0bca54138904895c39d38227a70c22"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import models\n",
    "\n",
    "kernel_size = (3,3)\n",
    "pool_size= (2,2)\n",
    "first_filters = 32\n",
    "second_filters = 64\n",
    "third_filters = 128\n",
    "\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.3\n",
    "\n",
    "#defining pretrained layer\n",
    "vgg_model = tf.keras.applications.vgg16.VGG16(weights = 'imagenet', include_top = False, input_shape = (96,96,3))\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "#adding pretrained layer\n",
    "model.add(vgg_model.layers[0])\n",
    "\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', ))\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size)) \n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "75cfc4fcb8dd3408d1c4fcf8cd85e0e2f5b611d7"
   },
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9de9715f49a63b55775b10abd2f461b395e23b5d"
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.0001), loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"model.h5\"\n",
    "#saves model after every epoch\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "#reduces learning rate if there is no change in val_acc for 2 epochs, by factor of half \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "                              \n",
    "                              \n",
    "callbacks = [checkpoint, reduce_lr]\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=20, verbose=1,\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa15a8afda3593973726e9087cbd98073041c908"
   },
   "source": [
    "validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "428bdf5b24ff8cef35012205c3f2eb37006fc9e9"
   },
   "outputs": [],
   "source": [
    "# using best epoch on validation\n",
    "\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "val_loss, val_acc = \\\n",
    "model.evaluate_generator(test_gen, \n",
    "                        steps=len(df_train_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_acc:', val_acc)\n",
    "\n",
    "predictions = model.predict_generator(test_gen, steps=len(df_train_val), verbose=1)\n",
    "#the validation set can be used to create a confusion matrix for presentation purposes#KIV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a10b51355f1aa8ae1f7148703791dc71f5f7e3e"
   },
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c91e56e9c45caa655f7e45ec98ae0c492ce5358e"
   },
   "outputs": [],
   "source": [
    "shutil.rmtree('base_dir')\n",
    "\n",
    "#create test dir\n",
    "\n",
    "#feed test images to test_dir\n",
    "test_dir = 'test_dir'\n",
    "os.mkdir(test_dir)\n",
    "test_images = os.path.join(test_dir, 'test_images')\n",
    "os.mkdir(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f98c94ea8355a6d56d3f4a2791934b3365ed7865"
   },
   "outputs": [],
   "source": [
    "# move test images into image_dir\n",
    "\n",
    "test_list = os.listdir('../input/test')\n",
    "    \n",
    "    \n",
    "for image in test_list:\n",
    "    \n",
    "\n",
    "    fname = image\n",
    "#     fname=fname+'.tif'\n",
    "    src = os.path.join('../input/test', fname)\n",
    "    dst = os.path.join(test_images, fname)\n",
    "    #copy\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6529facf2e4b60f4962fb0d08528e9f1ecd895a7"
   },
   "outputs": [],
   "source": [
    "test_path ='test_dir'\n",
    "\n",
    "\n",
    "test_gen = datagen.flow_from_directory(test_path,\n",
    "                                        target_size=(image_size,image_size),\n",
    "                                        batch_size=1,\n",
    "                                        class_mode='binary',\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "150f61e5b959bcb2589d330652e3b1989caa35c4"
   },
   "outputs": [],
   "source": [
    "num_test_images = 57458\n",
    "\n",
    "# make sure we are using the best epoch\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "predictions = model.predict_generator(test_gen, steps=num_test_images, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1346b4e4f22f053a5a70bef1f5edd1c2aee48404"
   },
   "outputs": [],
   "source": [
    "#inserting test preds into dataframe for submission csv\n",
    "\n",
    "df_preds = pd.DataFrame(predictions, columns=['no_tumor_tissue', 'has_tumor_tissue'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ff5fb65c49b505b405c726573dd9285664641bc1"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_filenames = test_gen.filenames\n",
    "df_preds['file_names'] = test_filenames\n",
    "\n",
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d04252577cd31825505fcbce69e7f3b6c052e35f"
   },
   "outputs": [],
   "source": [
    "\n",
    "#just want id, not .tif\n",
    "def remove_id(x):\n",
    "    \n",
    "    # split into a list\n",
    "    a = x.split('/')\n",
    "    # split into a list\n",
    "    b = a[1].split('.')\n",
    "    removed_id = b[0]\n",
    "    \n",
    "    return removed_id\n",
    "\n",
    "df_preds['id'] = df_preds['file_names'].apply(remove_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = df_preds['has_tumor_tissue']\n",
    "\n",
    "image_id = df_preds['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for submission to kaggle\n",
    "submission = pd.DataFrame({'id':image_id, \n",
    "                           'label':y_pred, \n",
    "                          }).set_index('id')\n",
    "\n",
    "submission.to_csv('results.csv', columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('test_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References/Acknowledgements\n",
    "\n",
    "\n",
    "I would like to thank the following sources for guiding me in developing this model:\n",
    "* https://www.kaggle.com/fmarazzi/baseline-keras-cnn-roc-fast-10min-0-925-lb\n",
    "* https://www.kaggle.com/bulentsiyah/histopathologic-cancer-detection-vgg16\n",
    "* https://www.hindawi.com/journals/cin/2017/2917536/\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
